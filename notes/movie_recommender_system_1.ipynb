{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "credits = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
    "# default value of heaad command is 5 ie 0 to 4\n",
    "movies.head()\n",
    "# we can give any N in the head command\n",
    "movies.head(1)\n",
    "credits.head()\n",
    "credits.head(1)\n",
    "# gives all the values present in cast column\n",
    "credits.head(1)[\"cast\"].values\n",
    "credits.head(1)[\"crew\"].values\n",
    "# merging the two databases on the basis of title column -- it can be done with either title or movie id\n",
    "movies = movies.merge(credits, on = \"title\")\n",
    "# shape will give number of rows and number of columns in a tuple form\n",
    "movies.shape\n",
    "movies.shape\n",
    "credits.shape\n",
    "# removing those columns which are not needed\n",
    "# number of different datas present in a particular column ie original language\n",
    "movies[\"original_language\"].value_counts()\n",
    "# The information contains\n",
    "# number of columns\n",
    "# column labels\n",
    "# column data types\n",
    "# memory usage\n",
    "# range index\n",
    "# number of cells in each column (non-null values).\n",
    "movies.info()\n",
    "movies = movies[[\"movie_id\", \"title\", \"overview\", \"genres\", \"keywords\", \"cast\", \"crew\"]]\n",
    "movies.head()\n",
    "# removing missing data and null data\n",
    "# isnull will find the columns whose data is null\n",
    "movies.isnull()\n",
    "movies.isnull().sum()\n",
    "# The dropna() method -- removes the rows that contains NULL values.\n",
    "# inplace -- default False. If True: the removing is done on the current DataFrame. If False: returns a copy where the removing is done.\n",
    "movies.dropna(inplace = True)\n",
    "movies.duplicated()\n",
    "# Pandas duplicated() method helps in analyzing duplicate values only. \n",
    "# It returns a boolean series which is True only for Unique elements.\n",
    "movies.duplicated().sum()\n",
    "# formatting all the columns\n",
    "# The iloc property -- gets, or sets, the value(s) of the specified indexes [rows, columns]\n",
    "movies.iloc[0].genres\n",
    "# we need to convert this list of dictionaries into a list only like [action,adventure,fantasy,science fiction]\n",
    "def convert(obj):\n",
    "    l = []\n",
    "    for i in obj:\n",
    "        l.append(i[\"name\"])\n",
    "    return l\n",
    "# the string indeces mut be integers\n",
    "# this code will return [\"action\", \"adventure\", \"fantasy\", \"science fiction\"]\n",
    "import ast\n",
    "ast.literal_eval('[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]')\n",
    "# since it is a string the function above is not running\n",
    "# so it is first needed to convert in list\n",
    "def convert(obj):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        l.append(i[\"name\"])\n",
    "    return l\n",
    "movies[\"genres\"].apply(convert)\n",
    "# func: .apply takes a function and applies it to all values of pandas series\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(convert)\n",
    "movies.head()\n",
    "movies[\"keywords\"]= movies[\"keywords\"].apply(convert)\n",
    "movies.head()\n",
    "# needed only first 3 actors of the dictionary\n",
    "movies[\"cast\"][0]\n",
    "def convert_3(obj):\n",
    "    l = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            l.append(i[\"name\"])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return l\n",
    "\n",
    "movies[\"cast\"] = movies[\"cast\"].apply(convert_3)\n",
    "movies.head(1)\n",
    "movies[\"crew\"][0]\n",
    "def fetch_director(obj):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i[\"job\"] == \"Director\":\n",
    "            l.append(i[\"name\"])\n",
    "            break\n",
    "    return l\n",
    "movies[\"crew\"].apply(fetch_director)\n",
    "movies[\"crew\"] = movies[\"crew\"].apply(fetch_director)\n",
    "movies.head(1)\n",
    "movies[\"overview\"][0]\n",
    "movies[\"overview\"].apply(lambda x:x.split())\n",
    "# string to list converter\n",
    "movies[\"overview\"] = movies[\"overview\"].apply(lambda x:x.split())\n",
    "movies.head()\n",
    "# the first name of the actors may be same which might confuse the model\n",
    "# thus removing the space is best method\n",
    "movies[\"genres\"].apply(lambda x:[i.replace(\" \", \"\")for i in x])\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(lambda x:[i.replace(\" \", \"\")for i in x])\n",
    "movies[\"keywords\"] = movies[\"keywords\"].apply(lambda x:[i.replace(\" \", \"\") for i in x])\n",
    "movies[\"cast\"] = movies[\"cast\"].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "movies[\"crew\"] = movies[\"crew\"].apply(lambda x:[i.replace(\" \",\"\")for i in x])\n",
    "movies[\"overview\"] = movies[\"overview\"].apply(lambda x:[i.replace(\" \", \"\") for i in x])\n",
    "movies.head()\n",
    "# making just one tags column with all the information needed for the data\n",
    "movies[\"tags\"] = movies[\"overview\"] + movies[\"genres\"] + movies[\"keywords\"] + movies[\"cast\"] + movies[\"crew\"]\n",
    "movies.head()\n",
    "# making a new database just with the required data\n",
    "new_df = movies[[\"movie_id\", \"title\", \"tags\"]]\n",
    "new_df.head()\n",
    "new_df[\"tags\"].apply(lambda x: \" \".join(x))\n",
    "# A lambda function is a small anonymous function.\n",
    "# A lambda function can take any number of arguments, but can only have one expression.\n",
    "# making strings into lists\n",
    "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x: \" \".join(x))\n",
    "new_df\n",
    "new_df[\"tags\"][0]\n",
    "# advised to convert it into lower case\n",
    "new_df[\"tags\"].apply(lambda x: x.lower())\n",
    "new_df[\"tags\"] = new_df[\"tags\"].apply(lambda x: x.lower())\n",
    "new_df\n",
    "\n",
    "\n",
    "# data vectorization\n",
    "# how can we say that these following movies are similar\n",
    "# we need to find the similarity between the tags to do that we need to find the similarity between words which can be done by counting the number of times that word occur in the given tag\n",
    "# we will conver the text into vectors\n",
    "# in 2d space we can make vectors which will have an x coordinate and a y coordinate\n",
    "# each movie will be considered as a vector\n",
    "# now vectors which are closer to each other will represent same movies or similar movies\n",
    "# we will use bag of wordsw vectorizatiopn technique\n",
    "# all the tags will be concatenated\n",
    "# 5000 most common words will be calculated \n",
    "# each tag will be checked with the the 5000 most common words list and a hashmap will be created\n",
    "# less most common words means faster vectorization\n",
    "# stop words will not be considered( stop words are those words which are not actually a part of the sentence or give meaning to the sentence -- and, a , but etc)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# max_features = how many wordsw for hash map need to be considered\n",
    "cv = CountVectorizer(max_features = 5000, stop_words = \"english\")\n",
    "#count vectorizer will by default return sparce matrix which needs to be converted into an array\n",
    "# so it will be explicedly converted to a numpy array\n",
    "vectors = cv.fit_transform(new_df[\"tags\"]).toarray()\n",
    "cv.fit_transform(new_df[\"tags\"]).toarray().shape\n",
    "vectors[1]\n",
    "cv.get_feature_names_out\n",
    "# corpes is the big list with all the words which were combined of the tags\n",
    "len(cv.get_feature_names_out())\n",
    "# actions and action form two words which need to be removed\n",
    "# stemming -- will remove this ambiguity and combine these words\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()  # object\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        ps.stem(i)\n",
    "\n",
    "ps.stem(\"dancing, dance, danced\")\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)\n",
    "new_df[\"tags\"] = new_df[\"tags\"].apply(stem)\n",
    "# 4806 movies have 4806 vectors and 5000 words\n",
    "# we need to calculate the distance of every mopvie with the other movies\n",
    "# greater the distance less the similarity\n",
    "# we will not calculate euclidian distance(tip to tip distance) we will calculate cosine distance(angular distance)\n",
    "# angle in closer to zero basically same vector\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(vectors)\n",
    "similarity = cosine_similarity(vectors)\n",
    "similarity.shape\n",
    "# this is the similarity of the first movie with the first movie\n",
    "similarity[0].shape\n",
    "# diagonal of similarities will be 1\n",
    "# we need to find the index of movie from the data\n",
    "new_df[new_df[\"title\"] == \"Avatar\"]   #.index[0]\n",
    "def recommend(input):\n",
    "    movie_index = new_df[new_df[\"title\"] == input].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    # sorting will loose the index position of the movie\n",
    "    # enumerate will be used\n",
    "    # reverse order since intial values will mostly be zero\n",
    "    # hey so that it can be done on the basis of second value not the first\n",
    "    movies_list = sorted(list(enumerate(distances)), reverse = True, key = lambda x:x[1])[0:20]\n",
    "    for i in movies_list:\n",
    "        print(new_df.iloc[i[0]].title)\n",
    "        \n",
    "recommend('Batman')\n",
    "# for finding the name again\n",
    "new_df.iloc[1216].title\n",
    "import pickle\n",
    "pickle.dump(new_df,open(\"movies.pkl\",\"wb\"))\n",
    "pickle.dump(new_df.to_dict(),open(\"movie_dict.pkl\",\"wb\"))\n",
    "pickle.dump(similarity,open(\"similarity.pkl\",\"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "189426530a3062aae6aee9e066914f10e43bb7a43a1c3e7a0b1c3c93ac05feeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
